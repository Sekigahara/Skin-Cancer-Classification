{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_base = ['benign', 'semi', 'malign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Folder Path\n",
    "train_folder_path = glob.glob(\"dataset_three_classes/train/*\")\n",
    "#test_folder_path = glob.glob(\"dataset_three_classes/test/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_by_path(folder_path, label_mapping):\n",
    "    def label_to_encode(label_name, label_mapping):\n",
    "        if label_name == 'benign':\n",
    "            return 0\n",
    "        if label_name == 'semi':\n",
    "            return 1\n",
    "        if label_name == 'malign':\n",
    "            return 2\n",
    "\n",
    "        return encode_label\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    paths = []\n",
    "\n",
    "    for idx, path in enumerate(folder_path):\n",
    "        # Load each specific image location\n",
    "        all_image_path = glob.glob(path + \"/*\")\n",
    "        # Extract label\n",
    "        # Fix path inconsistencies on windows\n",
    "        real_label = path.replace(\"\\\\\", \"/\").replace(\"//\", \"/\").split(\"/\")[2]\n",
    "        # Change label into encoded format\n",
    "        encode_label = label_to_encode(real_label, label_mapping)\n",
    "\n",
    "        # Loop through an array to load image\n",
    "        for idx2, img_path in enumerate(all_image_path):\n",
    "            # Load image\n",
    "            image = cv2.imread(img_path)\n",
    "            paths.append(img_path)\n",
    "            images.append(image)\n",
    "            labels.append(encode_label)\n",
    "        #print(all_image_path)\n",
    "\n",
    "    return np.array(images), np.array(labels), np.array(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andro\\AppData\\Local\\Temp/ipykernel_6900/585285212.py:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(images), np.array(labels), np.array(paths)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, label_train = get_image_by_path(train_folder_path, label_base)\n",
    "#x_test, y_test, label_test = get_image_by_path(test_folder_path, label_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=4518 (71.646%)\n",
      "Class=2, n=965 (15.303%)\n",
      "Class=1, n=823 (13.051%)\n",
      "Class Total each : 4518 index max : 0\n",
      "[0, 2, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4518, 965, 823]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_totals = []\n",
    "class_sort = []\n",
    "# Gather each classes total data and max classes information\n",
    "counter = Counter(y_train)\n",
    "for k, v in counter.items():\n",
    "    per= v / len(y_train) * 100\n",
    "    class_totals.append(v)\n",
    "    class_sort.append(k)\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "\n",
    "max_classes = max(class_totals)\n",
    "max_classes_idx = class_totals.index(max_classes)\n",
    "print(\"Class Total each : {} index max : {}\".format(max_classes, max_classes_idx))\n",
    "print(class_sort)\n",
    "class_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_combination(n_combination=2, first_group_length=1, second_group_length=1):\n",
    "    combination = []\n",
    "    \n",
    "    itr = 0\n",
    "    # Looping to generate n combination\n",
    "    # Only possible for 11 combination, if 11 combination has been fulfilled loop may go infinity\n",
    "    while itr < n_combination:\n",
    "        # Generate with range 0f 0-3 and 0-2\n",
    "        temp = [random.randrange(0, first_group_length), random.randrange(0, second_group_length)]\n",
    "        \n",
    "        # Avoid combination [0, 0]\n",
    "        if temp == [0, 0]:\n",
    "            continue\n",
    "        \n",
    "        # Assign for first iteration\n",
    "        if itr == 0:\n",
    "            combination.append(temp)\n",
    "            itr += 1\n",
    "        \n",
    "        # Assign for second and later iteration\n",
    "        if itr != 0:      \n",
    "            # Gather Information upwards/backward of array\n",
    "            isTheSame = False\n",
    "            for data in combination:\n",
    "                if data == temp:\n",
    "                    isTheSame = True\n",
    "                    break\n",
    "                    \n",
    "            # if no similiarity to backward array temp succesfully added\n",
    "            if isTheSame == False:\n",
    "                combination.append(temp)\n",
    "                itr += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return np.asarray(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_COMBINATION_MAPPING = [\n",
    "    ['None', 0],\n",
    "    ['gblur', 5],\n",
    "    ['gblur', 7],\n",
    "    ['gnoise', 10],\n",
    "    ['hflip', 0],\n",
    "    ['zoom', 1.5],\n",
    "    ['zoom', 2.0],\n",
    "]\n",
    "\n",
    "SECOND_COMBINATION_MAPPING = [\n",
    "    ['None', 0],\n",
    "    ['vflip', -1],\n",
    "    ['brightness', -30],\n",
    "    ['contrast', (0.8, 20)],\n",
    "    ['vflip', 1],\n",
    "    ['gcorrection', 1.9],\n",
    "    ['gcorrection', 2.25],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# First Group Augmentation\n",
    "def first_group(image, *argv, preference='hflip'):\n",
    "    if preference == 'hflip':\n",
    "        result = cv2.flip(image, 1)\n",
    "    elif preference == 'gnoise':\n",
    "        intensity = argv[0]\n",
    "        gauss = np.random.normal(0,intensity, image.size)\n",
    "        gauss = gauss.reshape(image.shape[0],image.shape[1],image.shape[2]).astype('uint8')\n",
    "        result = np.add(image, gauss)\n",
    "    elif preference == 'gblur':\n",
    "        kernel = (argv[0], argv[0])\n",
    "        result = cv2.GaussianBlur(image, kernel, 0)\n",
    "    elif preference == 'zoom':\n",
    "        zoom_factor = argv[0]\n",
    "        x, y, _ = image.shape\n",
    "\n",
    "        # Define new boundaries\n",
    "        x1 = int(0.5*x*(1-1/zoom_factor))\n",
    "        x2 = int(x-0.5*x*(1-1/zoom_factor))\n",
    "        y1 = int(0.5*y*(1-1/zoom_factor))\n",
    "        y2 = int(y-0.5*y*(1-1/zoom_factor))\n",
    "\n",
    "        result = image[y1:y2, x1:x2]\n",
    "        result = cv2.resize(result, None, fx=zoom_factor, fy=zoom_factor)\n",
    "    elif preference == 'None':\n",
    "        result = image\n",
    "\n",
    "    return result\n",
    "\n",
    "# Second Group Augmentation\n",
    "def second_group(image, *argv, preference='gcorrection'):\n",
    "\n",
    "    if preference == 'gcorrection':\n",
    "        gamma = argv[0]\n",
    "        invGamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "            for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "        result = cv2.LUT(image, table)\n",
    "    \n",
    "    elif preference == 'vflip':\n",
    "        rotate = argv[0]\n",
    "        result = cv2.flip(image, rotate)\n",
    "        return result\n",
    "\n",
    "    elif preference == 'hue':\n",
    "        hue_adjustment_value = argv[0]\n",
    "        temp = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype('float32')\n",
    "        (h , s, v) = cv2.split(temp)\n",
    "        h = cv2.add(h, hue_adjustment_value)\n",
    "        result = cv2.merge([h, s, v])\n",
    "        result = cv2.cvtColor(result.astype('uint8'), cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    elif preference == 'saturation':\n",
    "        saturation_adjustment_value = argv[0]\n",
    "        temp = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype('float32')\n",
    "        (h , s, v) = cv2.split(temp)\n",
    "        s = s * saturation_adjustment_value\n",
    "        s = np.clip(s, 0, 255)\n",
    "        result = cv2.merge([h, s, v])\n",
    "        result = cv2.cvtColor(result.astype('uint8'), cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    elif preference == 'brightness':\n",
    "        brightness = argv[0]\n",
    "        if brightness != 0:\n",
    "            if brightness > 0:\n",
    "                shadow = brightness\n",
    "                highlight = 255\n",
    "            else:\n",
    "                shadow = 0\n",
    "                highlight = 255 + brightness\n",
    "            alpha_b = (highlight - shadow)/255\n",
    "            gamma_b = shadow\n",
    "            buf = cv2.addWeighted(image, alpha_b, image, 0, gamma_b)\n",
    "        else:\n",
    "            buf = image.copy()\n",
    "            \n",
    "        return buf  \n",
    "            \n",
    "    elif preference == 'contrast':\n",
    "        # Float default is 1.5, int default 20 respectively\n",
    "        alpha, beta = argv[0]\n",
    "        return cv2.addWeighted(image, alpha, np.zeros(image.shape, image.dtype), 0, beta)\n",
    "    elif preference == 'None':\n",
    "        result = image\n",
    "\n",
    "    return result\n",
    "\n",
    "# Combination Handler\n",
    "def combination_handler(image, combinations):\n",
    "    first, second = combinations\n",
    "    first_pick, second_pick = FIRST_COMBINATION_MAPPING[first], SECOND_COMBINATION_MAPPING[second]\n",
    "    \n",
    "    image = first_group(image, first_pick[1], preference=first_pick[0])\n",
    "    image = second_group(image, second_pick[1], preference=second_pick[0])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_img = 0\n",
    "save_path = 'dataset_three_classes/train'\n",
    "\n",
    "distinct_id = 0\n",
    "for idx, class_total in enumerate(class_totals):\n",
    "    # Avoid max classes index\n",
    "    # The max classes count is used for reference\n",
    "    if idx == max_classes_idx:\n",
    "        continue\n",
    "    \n",
    "    # Find foldername within label\n",
    "    folder_label_name = label_base[class_sort[idx]]\n",
    "\n",
    "    # Gather required combination\n",
    "    required_combination = max_classes // class_total\n",
    "    # Get combination\n",
    "    combinations = generate_random_combination(n_combination=required_combination, first_group_length=7, second_group_length=7)\n",
    "    \n",
    "    # Loop over each combinations array\n",
    "    for idx_comb, combination in enumerate(combinations):\n",
    "        # Loop Through each x_train that had same label\n",
    "        for idx_img, image in enumerate(x_train):\n",
    "            if y_train[idx_img] != class_sort[idx]:\n",
    "                continue\n",
    "\n",
    "            # Proceed the augmentation\n",
    "            image = combination_handler(image, combination)\n",
    "\n",
    "            # Extract image name\n",
    "            real_image_name = label_train[idx_img].replace(\"\\\\\", \"/\").replace(\"//\", \"/\")\n",
    "            real_image_name = real_image_name.split(\".\")[0].split(\"/\")[3]\n",
    "\n",
    "            # Save back the augmentation result\n",
    "            image_name = str(distinct_id) + \"_augmented_\" + str(class_sort[idx]) + \"_\" + real_image_name + \".jpg\"\n",
    "            final_save_path = os.path.join(save_path, folder_label_name, image_name)\n",
    "            #print(final_save_path)\n",
    "            cv2.imwrite(final_save_path, image)\n",
    "\n",
    "            distinct_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85b3e9a93fd6d54902d8504db28d32c7c77deb13c32a16ffc61523ea758b36c8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('sekigahara')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
